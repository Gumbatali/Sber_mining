# streamlit_app.py
# Process Mining ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å –ø–æ–¥—Ç–∏–ø–∞–º–∏ (–ø–æ–∫–µ–π—Å–Ω–æ), PNG —Å —Ñ–æ–ª–ª–±—ç–∫–æ–º

import os
import io
import tempfile
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import streamlit as st

# --- –º—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ pm4py, —á—Ç–æ–±—ã –∞–ø–ø –Ω–µ –ø–∞–¥–∞–ª –Ω–∞ Cloud ---
try:
    import pm4py
    from pm4py.objects.log.util import dataframe_utils
    from pm4py.visualization.dfg import visualizer as dfg_visualizer
except ModuleNotFoundError:
    st.set_page_config(page_title="Process Mining ‚Äî –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
    st.error(
        "–ú–æ–¥—É–ª—å **pm4py** –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–ª—è Streamlit Cloud –¥–æ–±–∞–≤—å –≤ `requirements.txt` "
        "`pm4py>=2.7.11` (–ø–æ–¥ Python 3.13) –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ `graphviz` + `packages.txt: graphviz`."
    )
    st.stop()

import matplotlib.pyplot as plt
import shutil
import networkx as nx

st.set_page_config(page_title="Process Mining ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏", layout="wide")
st.title("üîç Process Mining ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (—Å –ø–æ–¥—Ç–∏–ø–∞–º–∏)")

# =========================
# –ó–∞–≥—Ä—É–∑–∫–∞
# =========================
with st.expander("‚öôÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", expanded=False):
    local_path = st.text_input("–ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É —Ñ–∞–π–ª—É (CSV/Parquet)", value="case-championship-last.parquet")
    csv_sep = st.text_input("–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å CSV", value=",")
    csv_enc = st.text_input("–ö–æ–¥–∏—Ä–æ–≤–∫–∞ CSV", value="utf-8")

uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Parquet", type=["csv", "parquet"])

@st.cache_data(show_spinner=False)
def load_upload(f, sep=",", enc="utf-8"):
    if f.name.lower().endswith(".csv"):
        return pd.read_csv(f, sep=sep, encoding=enc)
    return pd.read_parquet(f)

@st.cache_data(show_spinner=False)
def load_path(p, sep=",", enc="utf-8"):
    p_l = p.lower()
    if p_l.endswith(".csv"):
        return pd.read_csv(p, sep=sep, encoding=enc)
    elif p_l.endswith(".parquet") or p_l.endswith(".pq"):
        return pd.read_parquet(p)
    else:
        raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è .csv –∏ .parquet")

df = None
if uploaded is not None:
    df = load_upload(uploaded, csv_sep, csv_enc)
elif local_path.strip() and os.path.exists(local_path.strip()):
    df = load_path(local_path.strip(), csv_sep, csv_enc)
    st.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª: {local_path.strip()}")

if df is None or df.empty:
    st.info("‚¨ÜÔ∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª–æ–≥ –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å.")
    st.stop()

st.subheader("üìä –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä")
st.dataframe(df.head(), use_container_width=True)

# =========================
# –ú–∞–ø–ø–∏–Ω–≥ + –≤—Ä–µ–º—è (+ —Ä–µ—Å—É—Ä—Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è ping-pong –ø–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º)
# =========================
st.subheader("üß≠ –ú–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫")
cols = df.columns.tolist()
col_case = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –∫–µ–π—Å–∞", cols, index=0)
col_act  = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏", cols, index=min(1, len(cols)-1))
col_ts   = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏", cols, index=min(2, len(cols)-1))
col_res_opt = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Ä–µ—Å—É—Ä—Å–∞/–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)", ["<–Ω–µ—Ç>"] + cols, index=0)

with st.expander("üïí –ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏", expanded=False):
    date_hint = st.text_input("–§–æ—Ä–º–∞—Ç –¥–∞—Ç—ã (–æ–ø—Ü.) –Ω–∞–ø—Ä–∏–º–µ—Ä %Y-%m-%d %H:%M:%S", value="")
    coerce_ts = st.checkbox("–û—à–∏–±–æ—á–Ω—ã–µ –¥–∞—Ç—ã ‚Üí NaT", value=True)
    tz = st.text_input("–¢–∞–π–º–∑–æ–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä Europe/Moscow). –ü—É—Å—Ç–æ ‚Äî –Ω–µ –º–µ–Ω—è—Ç—å", value="")

use_resource = col_res_opt != "<–Ω–µ—Ç>"

keep_cols = [col_case, col_act, col_ts] + ([col_res_opt] if use_resource else [])
df = df[keep_cols].copy()
rename_map = {col_case: "case_id", col_act: "activity", col_ts: "timestamp"}
if use_resource:
    rename_map[col_res_opt] = "resource"
df = df.rename(columns=rename_map)

# to_datetime
if date_hint.strip():
    df["timestamp"] = pd.to_datetime(df["timestamp"], format=date_hint, errors=("coerce" if coerce_ts else "raise"))
else:
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors=("coerce" if coerce_ts else "raise"))

# TZ
if tz.strip():
    try:
        if df["timestamp"].dt.tz is None:
            df["timestamp"] = df["timestamp"].dt.tz_localize(tz, nonexistent="NaT", ambiguous="NaT")
        else:
            df["timestamp"] = df["timestamp"].dt.tz_convert(tz)
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–∞–π–º–∑–æ–Ω—É: {e}")

na_share = df["timestamp"].isna().mean()
if na_share > 0:
    st.warning(f"‚ö†Ô∏è {na_share:.1%} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π ‚Üí NaT (–±—É–¥—É—Ç –æ—Ç–±—Ä–æ—à–µ–Ω—ã).")
    df = df.dropna(subset=["timestamp"])

df["case_id"] = df["case_id"].astype(str).str.strip()
df["activity"] = df["activity"].astype(str).str.strip()
if use_resource:
    df["resource"] = df["resource"].astype(str).str.strip()
df = df[(df["case_id"] != "") & (df["activity"] != "")]
df = df.sort_values(["case_id", "timestamp"])
if df.groupby("case_id").size().max() < 2:
    st.error("–ù—É–∂–Ω–æ ‚â•2 —Å–æ–±—ã—Ç–∏—è –Ω–∞ –∫–µ–π—Å.")
    st.stop()

# =========================
# –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ
# =========================
# PM4Py event log
event_log = pm4py.format_dataframe(
    df,
    case_id="case_id",
    activity_key="activity",
    timestamp_key="timestamp",
    resource_key=("resource" if use_resource else None)
)
from pm4py.objects.log.util import dataframe_utils
event_log = dataframe_utils.convert_timestamp_columns_in_df(event_log)
if "time:timestamp" in event_log.columns:
    event_log = event_log.sort_values(["case:concept:name", "time:timestamp"])
else:
    event_log = event_log.sort_values(["case:concept:name"])
n_cases = event_log["case:concept:name"].nunique()
st.success(f"‚úÖ –°–æ–±—ã—Ç–∏–π: {len(event_log):,} ‚Ä¢ –ö–µ–π—Å–æ–≤: {n_cases:,}")

# –ú–µ–∂—à–∞–≥–æ–≤—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
df_sorted = df.copy()
df_sorted["next_activity"]  = df_sorted.groupby("case_id")["activity"].shift(-1)
df_sorted["next_timestamp"] = df_sorted.groupby("case_id")["timestamp"].shift(-1)
if use_resource:
    df_sorted["resource_next"] = df_sorted.groupby("case_id")["resource"].shift(-1)
df_sorted["delta_sec"] = (df_sorted["next_timestamp"] - df_sorted["timestamp"]).dt.total_seconds()
edges = df_sorted.dropna(subset=["next_activity", "delta_sec"]).copy()
edges["edge"] = list(zip(edges["activity"], edges["next_activity"]))

edge_stats = (
    edges.groupby("edge")["delta_sec"]
         .agg(median="median",
              p90=lambda s: np.percentile(s, 90),
              p95=lambda s: np.percentile(s, 95),
              p99=lambda s: np.percentile(s, 99),
              mean="mean", std="std", count="count")
         .reset_index()
)
edge_stats_dict = edge_stats.set_index("edge").to_dict(orient="index")
edge_median_map = {e: s["median"] for e, s in edge_stats_dict.items()}
edge_p95_map    = {e: s["p95"]    for e, s in edge_stats_dict.items()}
edge_p99_map    = {e: s["p99"]    for e, s in edge_stats_dict.items()}

def safe_pct(series, q, default=np.nan) -> float:
    s = pd.Series(series).dropna()
    return float(np.percentile(s, q)) if not s.empty else default

# =========================
# –ò–ù–î–ò–ö–ê–¢–û–†–´ –ò –ü–û–î–¢–ò–ü–´
# =========================
# ---------- 1) –¶–ò–ö–õ–´ / –ó–ê–¶–ò–ö–õ–ï–ù–ù–û–°–¢–¨ ----------
def loop_subtypes_for_case(sub: pd.DataFrame, use_res: bool) -> Dict[str, int]:
    """
    –ü–æ–¥—Ç–∏–ø—ã:
      - self_loops: A‚ÜíA (–≤ —Å–µ–±—è)
      - ping_pong: ABAB (–∏–ª–∏ BABA). –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ—Å—É—Ä—Å ‚Äî —Ç–∞–∫–∂–µ ¬´—Ä–µ—Å—É—Ä—Å–Ω—ã–π –ø–∏–Ω–≥-–ø–æ–Ω–≥¬ª (A@R1 ‚Üí A@R2 ‚Üí A@R1 ‚Üí A@R2)
      - returns_nonadj: –≤–æ–∑–≤—Ä–∞—Ç—ã –∫ –ø—Ä–æ–π–¥–µ–Ω–Ω—ã–º —à–∞–≥–∞–º (A ‚Ä¶ A, –Ω–µ —Å–æ—Å–µ–¥–Ω–∏–µ)
      - jump_to_prev_any: –ø–µ—Ä–µ—Ö–æ–¥ –≤ –ª—é–±–æ–π —Ä–∞–Ω–µ–µ –≤—Å—Ç—Ä–µ—á–∞–≤—à–∏–π—Å—è —à–∞–≥ (edge-¬´–æ—Ç–∫–∞—Ç¬ª)
      - back_to_start: –≤–æ–∑–≤—Ä–∞—Ç—ã –∫ —Å—Ç–∞—Ä—Ç–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (‚Ä¶ ‚Üí A0)
    """
    acts = sub["activity"].tolist()
    res  = sub["resource"].tolist() if use_res else None
    if not acts:
        return {k: 0 for k in
                ["self_loops", "ping_pong", "ping_pong_res", "returns_nonadj", "jump_to_prev_any", "back_to_start", "loop_score_advanced"]}

    # 1) self loops
    self_loops = sum(1 for i in range(len(acts)-1) if acts[i] == acts[i+1])

    # 2) ping-pong –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—è–º (ABAB, –¥–ª–∏–Ω–∞ –æ–∫–Ω–∞ >=4)
    ping_pong = 0
    i = 0
    while i+3 < len(acts):
        a, b, c, d = acts[i:i+4]
        if a != b and a == c and b == d:
            ping_pong += 1
            i += 2  # —Å–¥–≤–∏–≥ –Ω–∞ –ø–æ–ª-—à–∞–≥–∞, —á—Ç–æ–±—ã —Å—á–∏—Ç–∞—Ç—å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è —É–º–µ—Ä–µ–Ω–Ω–æ
        else:
            i += 1

    # 2b) —Ä–µ—Å—É—Ä—Å–Ω—ã–π –ø–∏–Ω–≥-–ø–æ–Ω–≥ (–æ–¥–Ω–∞ –∏ —Ç–∞ –∂–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –Ω–æ R1‚ÜîR2‚ÜîR1‚ÜîR2)
    ping_pong_res = 0
    if use_res:
        i = 0
        while i+3 < len(acts):
            a1, r1 = acts[i],   res[i]
            a2, r2 = acts[i+1], res[i+1]
            a3, r3 = acts[i+2], res[i+2]
            a4, r4 = acts[i+3], res[i+3]
            # –æ–¥–Ω–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –Ω–æ —Ä–µ—Å—É—Ä—Å—ã —á–µ—Ä–µ–¥—É—é—Ç—Å—è
            if a1 == a2 == a3 == a4 and len({r1, r2}) == 2 and r1 == r3 and r2 == r4:
                ping_pong_res += 1
                i += 2
            else:
                i += 1

    # 3) –≤–æ–∑–≤—Ä–∞—Ç—ã –∫ –ø—Ä–æ–π–¥–µ–Ω–Ω—ã–º —à–∞–≥–∞–º (–Ω–µ —Å–æ—Å–µ–¥–Ω–∏–µ A‚Ä¶A)
    returns_nonadj = 0
    last_pos = {}
    for i, a in enumerate(acts):
        if a in last_pos and i - last_pos[a] > 1:
            returns_nonadj += 1
        last_pos[a] = i

    # 4) ¬´–ø—Ä—ã–∂–æ–∫ –≤ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π —Ä–∞–Ω–Ω–∏–π —ç—Ç–∞–ø¬ª: –ø–µ—Ä–µ—Ö–æ–¥, –≥–¥–µ next_activity —É–∂–µ –≤—Å—Ç—Ä–µ—á–∞–ª–∞—Å—å —Ä–∞–Ω–µ–µ –≤ —Ç—Ä–∞—Å—Å–µ
    jump_to_prev_any = 0
    seen = set()
    for i in range(len(acts)-1):
        seen.add(acts[i])
        if acts[i+1] in seen and acts[i+1] != acts[i]:
            jump_to_prev_any += 1

    # 5) –≤–æ–∑–≤—Ä–∞—Ç –≤ –Ω–∞—á–∞–ª–æ (–ø–æ–≤—Ç–æ—Ä —Å—Ç–∞—Ä—Ç–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)
    start_act = acts[0]
    back_to_start = sum(1 for i in range(1, len(acts)) if acts[i] == start_act)

    loop_score_adv = self_loops + ping_pong + ping_pong_res + returns_nonadj + jump_to_prev_any + back_to_start
    return {
        "self_loops": self_loops,
        "ping_pong": ping_pong,
        "ping_pong_res": ping_pong_res,
        "returns_nonadj": returns_nonadj,
        "jump_to_prev_any": jump_to_prev_any,
        "back_to_start": back_to_start,
        "loop_score_advanced": loop_score_adv,
    }

loop_rows = []
for cid, g in df.groupby("case_id"):
    sc = loop_subtypes_for_case(g, use_resource)
    sc["case_id"] = cid
    loop_rows.append(sc)
loops_df = pd.DataFrame(loop_rows)

# –∞–≤—Ç–æ-–ø–æ—Ä–æ–≥–∏ –ø–æ –ø–æ–¥—Ç–∏–ø–∞–º (q75), –æ–±—â–∏–π ‚Äî –ø–æ —Å—É–º–º–µ (q75)
def q75(s): return int(np.ceil(safe_pct(s, 75, default=1)))
thr_self   = q75(loops_df["self_loops"])
thr_pp     = q75(loops_df["ping_pong"])
thr_ppr    = q75(loops_df["ping_pong_res"]) if use_resource else 1
thr_ret    = q75(loops_df["returns_nonadj"])
thr_jump   = q75(loops_df["jump_to_prev_any"])
thr_start  = q75(loops_df["back_to_start"])
thr_loop_total = q75(loops_df["loop_score_advanced"])

# ---------- 2) –î–õ–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –û–ü–ï–†–ê–¶–ò–ô ----------
# –ü–æ–¥—Ç–∏–ø—ã:
#   - single_spike: –µ—Å—Ç—å Œî > p99(edge) (—Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –¥–æ–ª–≥–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ)
#   - many_moderate: —Å—É–º–º–∞—Ä–Ω—ã–π overrun –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ median(edge) –≤–µ–ª–∏–∫ (q90)
#   - queue_before_activity: —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π ¬´—Ö–≤–æ—Å—Ç¬ª –ø–µ—Ä–µ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é (–º–Ω–æ–≥–æ –±–æ–ª—å—à–∏—Ö Œî –Ω–∞ –≤—Ö–æ–¥ –≤ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —à–∞–≥)
edge_median_map = {e: s["median"] for e, s in edge_stats_dict.items()}

def per_case_overruns(sub_edges: pd.DataFrame):
    single_spike = 0
    overrun_sum  = 0.0
    entry_waits  = {}  # –≤—Ö–æ–¥ –≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: ‚Ä¶ -> X
    for _, row in sub_edges.iterrows():
        e = (row["activity"], row["next_activity"])
        d = float(row["delta_sec"])
        med = edge_median_map.get(e, np.nan)
        p99 = edge_p99_map.get(e, np.nan)
        if not np.isnan(med):
            overrun_sum += max(0.0, d - med)
        if not np.isnan(p99) and d > p99:
            single_spike += 1
        # –∫–æ–ø–∏–º –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ –≤—Ö–æ–¥—É –≤ next_activity
        entry_waits[row["next_activity"]] = entry_waits.get(row["next_activity"], 0.0) + d
    # ¬´–æ—á–µ—Ä–µ–¥—å¬ª ‚Äî –µ—Å–ª–∏ –Ω–∞ 1 –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è ‚â• 40% —Å—É–º–º–∞—Ä–Ω–æ–≥–æ –æ–∂–∏–¥–∞–Ω–∏—è –∫–µ–π—Å–∞
    total_wait = sum(entry_waits.values())
    queue_flag = False
    queue_target = None
    if total_wait > 0:
        best_act = max(entry_waits, key=entry_waits.get)
        if entry_waits[best_act] / total_wait >= 0.40:
            queue_flag = True
            queue_target = best_act
    return single_spike, overrun_sum, queue_flag, queue_target

over_rows = []
for cid, g in df_sorted.groupby("case_id"):
    sub_edges = g.dropna(subset=["next_activity", "delta_sec"])
    ss, osum, qf, qtarget = per_case_overruns(sub_edges)
    over_rows.append({"case_id": cid, "single_spike_cnt": ss, "overrun_sum_sec": osum,
                      "queue_before_flag": qf, "queue_target": qtarget})
over_df = pd.DataFrame(over_rows)

thr_over_sum   = float(np.ceil(safe_pct(over_df["overrun_sum_sec"], 90, default=0.0)))
thr_over_spike = max(1, int(np.ceil(safe_pct(over_df["single_spike_cnt"], 75, default=1))))

# ---------- 3) –í–õ–ò–Ø–ù–ò–ï –ù–ê –ü–†–û–¶–ï–°–° ----------
# –ü–æ–¥—Ç–∏–ø—ã:
#   - impact_sum: Œ£(max(0, Œî - p95(edge))) ‚Äî –≤–∫–ª–∞–¥ –∫–µ–π—Å–∞ —Å–≤–µ—Ä—Ö —Ç–∏–ø–æ–≤—ã—Ö –æ–∂–∏–¥–∞–Ω–∏–π
#   - bottleneck_share: –¥–æ–ª—è –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –ø–æ –≥–ª–æ–±–∞–ª—å–Ω—ã–º ¬´—É–∑–∫–∏–º¬ª —Ä—ë–±—Ä–∞–º (top-k –ø–æ median)
#   - p95_exceed_count: —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∫–µ–π—Å –ø—Ä–µ–≤—ã—à–∞–ª p95 —Å–≤–æ–∏—Ö —Ä—ë–±–µ—Ä
k_bottlenecks = st.sidebar.number_input("Top-k —É–∑–∫–∏—Ö —Ä—ë–±–µ—Ä (–¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ –≤–ª–∏—è–Ω–∏—è)", min_value=1, value=10, step=1)
top_edges = set(edge_stats.sort_values("median", ascending=False).head(k_bottlenecks)["edge"].tolist())

def impact_for_case(sub_edges: pd.DataFrame):
    if sub_edges.empty:
        return 0.0, 0.0, 0
    imp_sum = 0.0
    in_bneck = 0
    exceed_cnt = 0
    n_edges = 0
    for _, row in sub_edges.iterrows():
        e = (row["activity"], row["next_activity"])
        d = float(row["delta_sec"])
        p95 = edge_p95_map.get(e, np.nan)
        n_edges += 1
        if e in top_edges:
            in_bneck += 1
        if not np.isnan(p95):
            exc = d - p95
            if exc > 0:
                imp_sum += exc
                exceed_cnt += 1
    share = in_bneck / n_edges if n_edges else 0.0
    return imp_sum, share, exceed_cnt

impact_rows = []
for cid, g in df_sorted.groupby("case_id"):
    sub_edges = g.dropna(subset=["next_activity", "delta_sec"])
    isum, share, excnt = impact_for_case(sub_edges)
    impact_rows.append({"case_id": cid, "impact_sum_sec": isum, "bneck_share": share, "p95_exceed_cnt": excnt})
impact_df = pd.DataFrame(impact_rows)

thr_impact_sum   = float(np.ceil(safe_pct(impact_df["impact_sum_sec"], 90, default=0.0)))
thr_bneck_share  = float(np.round(safe_pct(impact_df["bneck_share"], 90, default=0.5), 2))
thr_exceed_cnt   = int(np.ceil(safe_pct(impact_df["p95_exceed_cnt"], 75, default=1)))

# =========================
# –†–µ–∂–∏–º: –ê–≤—Ç–æ / –†—É—á–Ω–æ–π
# =========================
st.subheader("üß† –ü–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
mode = st.radio("–†–µ–∂–∏–º –ø–æ—Ä–æ–≥–æ–≤", ["–ê–≤—Ç–æ", "–†—É—á–Ω–æ–π"], horizontal=True, index=0)
if mode == "–†—É—á–Ω–æ–π":
    c1, c2, c3 = st.columns(3)
    with c1:
        thr_self  = st.number_input("–¶–∏–∫–ª—ã: –≤ —Å–µ–±—è (‚â•)", 0, value=int(thr_self))
        thr_pp    = st.number_input("–¶–∏–∫–ª—ã: –ø–∏–Ω–≥-–ø–æ–Ω–≥ (‚â•)", 0, value=int(thr_pp))
        if use_resource:
            thr_ppr = st.number_input("–¶–∏–∫–ª—ã: —Ä–µ—Å—É—Ä—Å–Ω—ã–π –ø–∏–Ω–≥-–ø–æ–Ω–≥ (‚â•)", 0, value=int(thr_ppr))
    with c2:
        thr_ret   = st.number_input("–¶–∏–∫–ª—ã: –≤–æ–∑–≤—Ä–∞—Ç—ã A‚Ä¶A (‚â•)", 0, value=int(thr_ret))
        thr_jump  = st.number_input("–¶–∏–∫–ª—ã: –ø—Ä—ã–∂–∫–∏ –≤ —Ä–∞–Ω–Ω–∏–µ —ç—Ç–∞–ø—ã (‚â•)", 0, value=int(thr_jump))
        thr_start = st.number_input("–¶–∏–∫–ª—ã: –≤–æ–∑–≤—Ä–∞—Ç—ã –≤ –Ω–∞—á–∞–ª–æ (‚â•)", 0, value=int(thr_start))
    with c3:
        thr_loop_total = st.number_input("–¶–∏–∫–ª—ã: —Å—É–º–º–∞—Ä–Ω—ã–π score (‚â•)", 0, value=int(thr_loop_total))
        thr_over_sum   = st.number_input("–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: Œ£ overrun, —Å–µ–∫ (‚â•)", 0, value=int(thr_over_sum), step=10)
        thr_over_spike = st.number_input("–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è (—à—Ç ‚â•)", 0, value=int(thr_over_spike))
        thr_impact_sum = st.number_input("–í–ª–∏—è–Ω–∏–µ: impact_sum (—Å–µ–∫ ‚â•)", 0, value=int(thr_impact_sum), step=10)
        thr_bneck_share = st.number_input("–í–ª–∏—è–Ω–∏–µ: –¥–æ–ª—è —É–∑–∫–∏—Ö —Ä—ë–±–µ—Ä (‚â•)", 0.0, 1.0, value=float(thr_bneck_share), step=0.05)
        thr_exceed_cnt  = st.number_input("–í–ª–∏—è–Ω–∏–µ: –ø—Ä–µ–≤—ã—à–µ–Ω–∏–π p95 (—à—Ç ‚â•)", 0, value=int(thr_exceed_cnt))

max_show = st.slider("–°–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤-¬´–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤¬ª –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å", 1, 20, 5)

# =========================
# –§–õ–ê–ì–ò (–≤—Å–µ –∫–µ–π—Å—ã —Å—á–∏—Ç–∞—é—Ç—Å—è –Ω–∞ –±—ç–∫–µ)
# =========================
loops_merge = loops_df.copy()
loops_merge["flag_self"]   = loops_merge["self_loops"]         >= thr_self
loops_merge["flag_pp"]     = loops_merge["ping_pong"]           >= thr_pp
loops_merge["flag_ppr"]    = (loops_merge["ping_pong_res"]     >= thr_ppr) if use_resource else False
loops_merge["flag_ret"]    = loops_merge["returns_nonadj"]      >= thr_ret
loops_merge["flag_jump"]   = loops_merge["jump_to_prev_any"]    >= thr_jump
loops_merge["flag_start"]  = loops_merge["back_to_start"]       >= thr_start
loops_merge["flag_loop"]   = loops_merge["loop_score_advanced"] >= thr_loop_total

over_merge = over_df.copy()
over_merge["flag_over_sum"]   = over_merge["overrun_sum_sec"]  >= thr_over_sum
over_merge["flag_over_spike"] = over_merge["single_spike_cnt"] >= thr_over_spike
over_merge["flag_queue"]      = over_merge["queue_before_flag"].fillna(False)

impact_merge = impact_df.copy()
impact_merge["flag_imp_sum"]  = impact_merge["impact_sum_sec"] >= thr_impact_sum
impact_merge["flag_imp_share"] = impact_merge["bneck_share"]   >= thr_bneck_share
impact_merge["flag_imp_exceed"] = impact_merge["p95_exceed_cnt"] >= thr_exceed_cnt

summary = (loops_merge[["case_id", "flag_self","flag_pp","flag_ppr","flag_ret","flag_jump","flag_start","flag_loop"]]
           .merge(over_merge[["case_id","flag_over_sum","flag_over_spike","flag_queue"]], on="case_id", how="outer")
           .merge(impact_merge[["case_id","flag_imp_sum","flag_imp_share","flag_imp_exceed"]], on="case_id", how="outer"))
summary = summary.fillna(False)
summary["any_flag"] = summary.drop(columns=["case_id"]).any(axis=1)

def download_df_button(df_to_dl: pd.DataFrame, filename: str, label: str):
    csv = df_to_dl.to_csv(index=False).encode("utf-8")
    st.download_button(label, csv, file_name=filename, mime="text/csv")

# =========================
# –í–´–í–û–î (—Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã + –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã)
# =========================
st.header("üß™ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º –∏ –ø–æ–¥—Ç–∏–ø–∞–º")

def show_section(title: str, df_bad: pd.DataFrame, sort_cols, fmt_row, csv_name: str):
    st.subheader(title)
    n_bad = int(df_bad.shape[0])
    st.write(f"–ù–∞–ª–∏—á–∏–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: **{'–î–∞' if n_bad>0 else '–ù–µ—Ç'}**  ‚Ä¢ –ó–∞—Ç—Ä–æ–Ω—É—Ç–æ –∫–µ–π—Å–æ–≤: **{n_bad}** –∏–∑ {n_cases}")
    if n_bad > 0:
        show = df_bad.sort_values(sort_cols, ascending=False).head(max_show)
        st.markdown("**–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–µ–π—Å—ã (–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞):**")
        for _, r in show.iterrows():
            st.markdown(fmt_row(r))
        with st.expander("‚¨áÔ∏è –í—ã–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞"):
            download_df_button(df_bad.sort_values(sort_cols, ascending=False), csv_name, "–°–∫–∞—á–∞—Ç—å CSV")

# --- –¶–∏–∫–ª—ã: –æ–±—â–∏–π —Ñ–ª–∞–≥ ---
show_section(
    "1) –¶–∏–∫–ª—ã ‚Äî —Å—É–º–º–∞—Ä–Ω—ã–π score",
    loops_merge[loops_merge["flag_loop"]],
    ["loop_score_advanced"],
    lambda r: f"- **{r['case_id']}** ‚Äî score={int(r['loop_score_advanced'])} (–≤ —Å–µ–±—è={int(r['self_loops'])}, "
              f"–ø–∏–Ω–≥-–ø–æ–Ω–≥={int(r['ping_pong'])}{', —Ä–µ—Å—É—Ä—Å–Ω—ã–π='+str(int(r['ping_pong_res'])) if use_resource else ''}, "
              f"–≤–æ–∑–≤—Ä–∞—Ç—ã={int(r['returns_nonadj'])}, –ø—Ä—ã–∂–∫–∏={int(r['jump_to_prev_any'])}, –≤ –Ω–∞—á–∞–ª–æ={int(r['back_to_start'])})",
    "ineff_cycles_total.csv"
)

# --- –¶–∏–∫–ª—ã: –ø–æ–¥—Ç–∏–ø—ã –æ—Ç–¥–µ–ª—å–Ω–æ ---
show_section(
    "1.1) –¶–∏–∫–ª—ã ‚Äî –≤ —Å–µ–±—è (A‚ÜíA)",
    loops_merge[loops_merge["flag_self"]][["case_id","self_loops"]],
    ["self_loops"],
    lambda r: f"- **{r['case_id']}** ‚Äî A‚ÜíA: {int(r['self_loops'])}",
    "ineff_cycle_self.csv"
)
show_section(
    "1.2) –¶–∏–∫–ª—ã ‚Äî –ø–∏–Ω–≥-–ø–æ–Ω–≥ (ABAB)",
    loops_merge[loops_merge["flag_pp"]][["case_id","ping_pong"]],
    ["ping_pong"],
    lambda r: f"- **{r['case_id']}** ‚Äî ABAB: {int(r['ping_pong'])}",
    "ineff_cycle_pingpong.csv"
)
if use_resource:
    show_section(
        "1.3) –¶–∏–∫–ª—ã ‚Äî —Ä–µ—Å—É—Ä—Å–Ω—ã–π –ø–∏–Ω–≥-–ø–æ–Ω–≥ (A@R1‚ÜîA@R2)",
        loops_merge[loops_merge["flag_ppr"]][["case_id","ping_pong_res"]],
        ["ping_pong_res"],
        lambda r: f"- **{r['case_id']}** ‚Äî —Ä–µ—Å—É—Ä—Å–Ω—ã–π ABAB: {int(r['ping_pong_res'])}",
        "ineff_cycle_pingpong_resource.csv"
    )
show_section(
    "1.4) –¶–∏–∫–ª—ã ‚Äî –≤–æ–∑–≤—Ä–∞—Ç –∫ –ø—Ä–æ–π–¥–µ–Ω–Ω–æ–º—É —à–∞–≥—É (A‚Ä¶A, –Ω–µ —Å–æ—Å–µ–¥–Ω–∏–µ)",
    loops_merge[loops_merge["flag_ret"]][["case_id","returns_nonadj"]],
    ["returns_nonadj"],
    lambda r: f"- **{r['case_id']}** ‚Äî –≤–æ–∑–≤—Ä–∞—Ç–æ–≤: {int(r['returns_nonadj'])}",
    "ineff_cycle_returns.csv"
)
show_section(
    "1.5) –¶–∏–∫–ª—ã ‚Äî –ø—Ä—ã–∂–∫–∏ –≤ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π —Ä–∞–Ω–Ω–∏–π —ç—Ç–∞–ø",
    loops_merge[loops_merge["flag_jump"]][["case_id","jump_to_prev_any"]],
    ["jump_to_prev_any"],
    lambda r: f"- **{r['case_id']}** ‚Äî ¬´–æ—Ç–∫–∞—Ç–æ–≤¬ª –ø–µ—Ä–µ—Ö–æ–¥–æ–º: {int(r['jump_to_prev_any'])}",
    "ineff_cycle_backjumps.csv"
)
show_section(
    "1.6) –¶–∏–∫–ª—ã ‚Äî –≤–æ–∑–≤—Ä–∞—Ç –≤ –Ω–∞—á–∞–ª–æ",
    loops_merge[loops_merge["flag_start"]][["case_id","back_to_start"]],
    ["back_to_start"],
    lambda r: f"- **{r['case_id']}** ‚Äî –≤–æ–∑–≤—Ä–∞—Ç–æ–≤ –∫ —Å—Ç–∞—Ä—Ç–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {int(r['back_to_start'])}",
    "ineff_cycle_back_to_start.csv"
)

# --- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–π: –ø–æ–¥—Ç–∏–ø—ã ---
show_section(
    "2) –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚Äî —Å—É–º–º–∞—Ä–Ω—ã–π –ø–µ—Ä–µ—Ä–∞—Å—Ö–æ–¥",
    over_merge[over_merge["flag_over_sum"]][["case_id","overrun_sum_sec"]],
    ["overrun_sum_sec"],
    lambda r: f"- **{r['case_id']}** ‚Äî Œ£ overrun={int(r['overrun_sum_sec'])} —Å–µ–∫",
    "ineff_duration_overrun.csv"
)
show_section(
    "2.1) –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚Äî —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è (Œî > p99(edge))",
    over_merge[over_merge["flag_over_spike"]][["case_id","single_spike_cnt"]],
    ["single_spike_cnt"],
    lambda r: f"- **{r['case_id']}** ‚Äî —ç–∫—Å—Ç—Ä–µ–º—É–º–æ–≤: {int(r['single_spike_cnt'])}",
    "ineff_duration_spikes.csv"
)
show_section(
    "2.2) –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚Äî ¬´–æ—á–µ—Ä–µ–¥—å¬ª –ø–µ—Ä–µ–¥ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é",
    over_merge[over_merge["flag_queue"]][["case_id","queue_target"]],
    ["queue_target"],
    lambda r: f"- **{r['case_id']}** ‚Äî –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–µ—Ä–µ–¥: **{r['queue_target']}**",
    "ineff_duration_queue.csv"
)

# --- –í–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å: –ø–æ–¥—Ç–∏–ø—ã ---
show_section(
    "3) –í–ª–∏—è–Ω–∏–µ ‚Äî impact_sum (—Å–≤–µ—Ä—Ö p95)",
    impact_merge[impact_merge["flag_imp_sum"]][["case_id","impact_sum_sec"]],
    ["impact_sum_sec"],
    lambda r: f"- **{r['case_id']}** ‚Äî impact_sum={int(r['impact_sum_sec'])} —Å–µ–∫",
    "ineff_impact_sum.csv"
)
show_section(
    "3.1) –í–ª–∏—è–Ω–∏–µ ‚Äî –¥–æ–ª—è —Ä—ë–±–µ—Ä –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö ¬´—É–∑–∫–∏—Ö¬ª",
    impact_merge[impact_merge["flag_imp_share"]][["case_id","bneck_share"]],
    ["bneck_share"],
    lambda r: f"- **{r['case_id']}** ‚Äî –¥–æ–ª—è —É–∑–∫–∏—Ö —Ä—ë–±–µ—Ä={r['bneck_share']:.2f}",
    "ineff_impact_share.csv"
)
show_section(
    "3.2) –í–ª–∏—è–Ω–∏–µ ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–π p95",
    impact_merge[impact_merge["flag_imp_exceed"]][["case_id","p95_exceed_cnt"]],
    ["p95_exceed_cnt"],
    lambda r: f"- **{r['case_id']}** ‚Äî –ø—Ä–µ–≤—ã—à–µ–Ω–∏–π p95: {int(r['p95_exceed_cnt'])}",
    "ineff_impact_exceed.csv"
)

# =========================
# –°–≤–æ–¥–∫–∞ —Ñ–∞–∫—Ç–æ–≤
# =========================
st.header("üìã –°–≤–æ–¥–∫–∞ —Ñ–∞–∫—Ç–æ–≤")
total_any = int(summary["any_flag"].sum())
st.write(
    f"- –¶–∏–∫–ª—ã (–ª—é–±–æ–π –ø–æ–¥—Ç–∏–ø –∏–ª–∏ —Å—É–º–º–∞—Ä–Ω—ã–π score): **{int(loops_merge[['flag_self','flag_pp','flag_ppr','flag_ret','flag_jump','flag_start','flag_loop']].any(axis=1).sum())}** –∫–µ–π—Å–æ–≤.\n"
    f"- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–∫–∞–∫–æ–π-–ª–∏–±–æ –ø–æ–¥—Ç–∏–ø): **{int(over_merge[['flag_over_sum','flag_over_spike','flag_queue']].any(axis=1).sum())}** –∫–µ–π—Å–æ–≤.\n"
    f"- –í–ª–∏—è–Ω–∏–µ (–∫–∞–∫–æ–π-–ª–∏–±–æ –ø–æ–¥—Ç–∏–ø): **{int(impact_merge[['flag_imp_sum','flag_imp_share','flag_imp_exceed']].any(axis=1).sum())}** –∫–µ–π—Å–æ–≤.\n"
    f"- –õ—é–±–∞—è –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: **{total_any}** –∏–∑ {n_cases}."
)
with st.expander("‚¨áÔ∏è –≠–∫—Å–ø–æ—Ä—Ç –ø–æ–ª–Ω–æ–π —Å–≤–æ–¥–∫–∏ –ø–æ —Ñ–ª–∞–≥–∞–º"):
    download_df_button(summary, "ineff_summary_all_flags.csv", "–°–∫–∞—á–∞—Ç—å CSV")

# =========================
# DFG + PNG —ç–∫—Å–ø–æ—Ä—Ç (graphviz / fallback)
# =========================
with st.expander("üìå –ö–∞—Ä—Ç–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ (DFG) –∏ —ç–∫—Å–ø–æ—Ä—Ç PNG", expanded=False):
    dfg_mode = st.radio("–ú–µ—Ç—Ä–∏–∫–∞ –∫–∞—Ä—Ç—ã", ["Frequency", "Performance"], horizontal=True, key="dfg_mode")
    if dfg_mode == "Frequency":
        dfg, sa, ea = pm4py.discover_dfg(event_log)
        variant = dfg_visualizer.Variants.FREQUENCY
    else:
        dfg, sa, ea = pm4py.discover_performance_dfg(event_log)
        variant = dfg_visualizer.Variants.PERFORMANCE
    gviz = dfg_visualizer.apply(dfg, log=event_log, variant=variant, parameters={"start_activities": sa, "end_activities": ea})
    st.graphviz_chart(gviz.source, use_container_width=True)

    st.download_button("‚¨áÔ∏è DOT", gviz.source.encode("utf-8"), file_name="process_dfg.dot", mime="text/plain")

    has_dot = shutil.which("dot") is not None
    if has_dot:
        try:
            with tempfile.TemporaryDirectory() as tmpd:
                outpath = os.path.join(tmpd, "process_dfg")
                gviz.render(filename=outpath, format="png", cleanup=True)
                with open(outpath + ".png", "rb") as f:
                    st.download_button("‚¨áÔ∏è PNG (graphviz)", f, file_name="process_dfg.png", mime="image/png")
        except Exception as e:
            st.warning(f"PNG —á–µ—Ä–µ–∑ graphviz –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")

    if not has_dot:
        st.info("Graphviz ('dot') –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Ä–µ–Ω–¥–µ—Ä—é —É–ø—Ä–æ—â—ë–Ω–Ω—ã–π PNG.")
        try:
            # –ì–æ—Ç–æ–≤–∏–º –≥—Ä–∞—Ñ –¥–ª—è —Ñ–æ–ª–ª–±—ç–∫–∞
            G = nx.DiGraph()
            for (u, v), w in dfg.items():
                G.add_edge(str(u), str(v), weight=w)
            pos = nx.spring_layout(G, k=1.2, seed=42)
            fig, ax = plt.subplots(figsize=(12, 6))
            nx.draw_networkx_nodes(G, pos, node_size=1200, ax=ax)
            nx.draw_networkx_labels(G, pos, font_size=8, ax=ax)
            nx.draw_networkx_edges(G, pos, arrows=True, arrowstyle='-|>', ax=ax)
            edge_labels = {(u, v): f"{data.get('weight', '')}" for u, v, data in G.edges(data=True)}
            nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=7, ax=ax)
            ax.axis('off')
            buf = io.BytesIO()
            plt.tight_layout()
            fig.savefig(buf, format="png", dpi=200)
            buf.seek(0)
            st.download_button("‚¨áÔ∏è PNG (fallback)", buf, file_name="process_dfg_fallback.png", mime="image/png")
            st.pyplot(fig, use_container_width=True)
        except Exception as e:
            st.warning(f"–§–æ–ª–ª–±—ç–∫ PNG –Ω–µ —É–¥–∞–ª—Å—è: {e}. –ü–æ—Å—Ç–∞–≤—å `graphviz`.")
