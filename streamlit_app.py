# streamlit_app.py
# Process Mining ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å –ø–æ–¥—Ç–∏–ø–∞–º–∏ + –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π DFG + –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π PNG + Bottleneck-–∞–Ω–∞–ª–∏–∑

import os
import io
import tempfile
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import streamlit as st

# --- –º—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ pm4py ---
try:
    import pm4py
    from pm4py.objects.log.util import dataframe_utils
    from pm4py.visualization.dfg import visualizer as dfg_visualizer
except ModuleNotFoundError:
    st.set_page_config(page_title="Process Mining ‚Äî –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
    st.error(
        "–ú–æ–¥—É–ª—å **pm4py** –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –í Streamlit Cloud –¥–æ–±–∞–≤—å –≤ `requirements.txt` "
        "`pm4py>=2.7.11` –∏ (–æ–ø—Ü.) `graphviz`; –≤ `packages.txt` ‚Äî `graphviz`."
    )
    st.stop()

import matplotlib.pyplot as plt
import shutil
import networkx as nx

st.set_page_config(page_title="Process Mining ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏", layout="wide")
st.title("üîç Process Mining ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (—Å –ø–æ–¥—Ç–∏–ø–∞–º–∏ + bottlenecks)")

# =========================
# –ó–∞–≥—Ä—É–∑–∫–∞
# =========================
with st.expander("‚öôÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", expanded=False):
    local_path = st.text_input("–ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É —Ñ–∞–π–ª—É (CSV/Parquet)", value="case-championship-last.parquet")
    csv_sep = st.text_input("–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å CSV", value=",")
    csv_enc = st.text_input("–ö–æ–¥–∏—Ä–æ–≤–∫–∞ CSV", value="utf-8")

uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Parquet", type=["csv", "parquet"])

@st.cache_data(show_spinner=False)
def load_upload(f, sep=",", enc="utf-8"):
    if f.name.lower().endswith(".csv"):
        return pd.read_csv(f, sep=sep, encoding=enc)
    return pd.read_parquet(f)

@st.cache_data(show_spinner=False)
def load_path(p, sep=",", enc="utf-8"):
    p_l = p.lower()
    if p_l.endswith(".csv"):
        return pd.read_csv(p, sep=sep, encoding=enc)
    elif p_l.endswith(".parquet") or p_l.endswith(".pq"):
        return pd.read_parquet(p)
    else:
        raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è .csv –∏ .parquet")

df = None
if uploaded is not None:
    df = load_upload(uploaded, csv_sep, csv_enc)
elif local_path.strip() and os.path.exists(local_path.strip()):
    df = load_path(local_path.strip(), csv_sep, csv_enc)
    st.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª: {local_path.strip()}")

if df is None or df.empty:
    st.info("‚¨ÜÔ∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª–æ–≥ –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å.")
    st.stop()

st.subheader("üìä –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä")
st.dataframe(df.head(), use_container_width=True)

# =========================
# –ú–∞–ø–ø–∏–Ω–≥ + –≤—Ä–µ–º—è + —Ä–µ—Å—É—Ä—Å
# =========================
st.subheader("üß≠ –ú–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫")
cols = df.columns.tolist()
col_case = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –∫–µ–π—Å–∞", cols, index=0)
col_act  = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏", cols, index=min(1, len(cols)-1))
col_ts   = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏", cols, index=min(2, len(cols)-1))
col_res_opt = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Ä–µ—Å—É—Ä—Å–∞/–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)", ["<–Ω–µ—Ç>"] + cols, index=0)

with st.expander("üïí –ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏", expanded=False):
    date_hint = st.text_input("–§–æ—Ä–º–∞—Ç –¥–∞—Ç—ã (–æ–ø—Ü.) –Ω–∞–ø—Ä–∏–º–µ—Ä %Y-%m-%d %H:%M:%S", value="")
    coerce_ts = st.checkbox("–û—à–∏–±–æ—á–Ω—ã–µ –¥–∞—Ç—ã ‚Üí NaT", value=True)
    tz = st.text_input("–¢–∞–π–º–∑–æ–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä Europe/Moscow). –ü—É—Å—Ç–æ ‚Äî –Ω–µ –º–µ–Ω—è—Ç—å", value="")

use_resource = col_res_opt != "<–Ω–µ—Ç>"

keep_cols = [col_case, col_act, col_ts] + ([col_res_opt] if use_resource else [])
df = df[keep_cols].copy()
rename_map = {col_case: "case_id", col_act: "activity", col_ts: "timestamp"}
if use_resource:
    rename_map[col_res_opt] = "resource"
df = df.rename(columns=rename_map)

# to_datetime
if date_hint.strip():
    df["timestamp"] = pd.to_datetime(df["timestamp"], format=date_hint, errors=("coerce" if coerce_ts else "raise"))
else:
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors=("coerce" if coerce_ts else "raise"))

# TZ
if tz.strip():
    try:
        if df["timestamp"].dt.tz is None:
            df["timestamp"] = df["timestamp"].dt.tz_localize(tz, nonexistent="NaT", ambiguous="NaT")
        else:
            df["timestamp"] = df["timestamp"].dt.tz_convert(tz)
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–∞–π–º–∑–æ–Ω—É: {e}")

na_share = df["timestamp"].isna().mean()
if na_share > 0:
    st.warning(f"‚ö†Ô∏è {na_share:.1%} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π ‚Üí NaT (–±—É–¥—É—Ç –æ—Ç–±—Ä–æ—à–µ–Ω—ã).")
    df = df.dropna(subset=["timestamp"])

df["case_id"] = df["case_id"].astype(str).str.strip()
df["activity"] = df["activity"].astype(str).str.strip()
if use_resource:
    df["resource"] = df["resource"].astype(str).str.strip()
df = df[(df["case_id"] != "") & (df["activity"] != "")]
df = df.sort_values(["case_id", "timestamp"])
if df.groupby("case_id").size().max() < 2:
    st.error("–ù—É–∂–Ω–æ ‚â•2 —Å–æ–±—ã—Ç–∏—è –Ω–∞ –∫–µ–π—Å.")
    st.stop()

# =========================
# –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ
# =========================
# ‚úÖ –ü–æ–¥–∞—ë–º resource_key —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –æ–Ω –µ—Å—Ç—å
fmt_kwargs = dict(case_id="case_id", activity_key="activity", timestamp_key="timestamp")
if use_resource: fmt_kwargs["resource_key"] = "resource"
event_log = pm4py.format_dataframe(df, **fmt_kwargs)

event_log = dataframe_utils.convert_timestamp_columns_in_df(event_log)
if "time:timestamp" in event_log.columns:
    event_log = event_log.sort_values(["case:concept:name", "time:timestamp"])
else:
    event_log = event_log.sort_values(["case:concept:name"])
n_cases = event_log["case:concept:name"].nunique()
st.success(f"‚úÖ –°–æ–±—ã—Ç–∏–π: {len(event_log):,} ‚Ä¢ –ö–µ–π—Å–æ–≤: {n_cases:,}")

# –ú–µ–∂—à–∞–≥–æ–≤—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
df_sorted = df.copy()
df_sorted["next_activity"]  = df_sorted.groupby("case_id")["activity"].shift(-1)
df_sorted["next_timestamp"] = df_sorted.groupby("case_id")["timestamp"].shift(-1)
if use_resource:
    df_sorted["resource_next"] = df_sorted.groupby("case_id")["resource"].shift(-1)
df_sorted["delta_sec"] = (df_sorted["next_timestamp"] - df_sorted["timestamp"]).dt.total_seconds()
edges = df_sorted.dropna(subset=["next_activity", "delta_sec"]).copy()
edges["edge"] = list(zip(edges["activity"], edges["next_activity"]))

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä—ë–±–µ—Ä
edge_stats = (
    edges.groupby("edge")["delta_sec"]
         .agg(median="median",
              p90=lambda s: np.percentile(s, 90),
              p95=lambda s: np.percentile(s, 95),
              p99=lambda s: np.percentile(s, 99),
              mean="mean", std="std", count="count")
         .reset_index()
)
edge_stats_dict = edge_stats.set_index("edge").to_dict(orient="index")
edge_median_map = {e: s["median"] for e, s in edge_stats_dict.items()}
edge_p95_map    = {e: s["p95"]    for e, s in edge_stats_dict.items()}
edge_p99_map    = {e: s["p99"]    for e, s in edge_stats_dict.items()}

def safe_pct(series, q, default=np.nan) -> float:
    s = pd.Series(series).dropna()
    return float(np.percentile(s, q)) if not s.empty else default

# =========================
# 1) –¶–ò–ö–õ–´ ‚Äî –ø–æ–¥—Ç–∏–ø—ã
# =========================
def loop_subtypes_for_case(sub: pd.DataFrame, use_res: bool) -> Dict[str, int]:
    acts = sub["activity"].tolist()
    res  = sub["resource"].tolist() if use_res else None
    if not acts:
        return {k: 0 for k in
                ["self_loops","ping_pong","ping_pong_res","returns_nonadj","jump_to_prev_any","back_to_start","loop_score_advanced"]}
    self_loops = sum(1 for i in range(len(acts)-1) if acts[i] == acts[i+1])
    # ping-pong ABAB
    ping_pong = 0; i = 0
    while i+3 < len(acts):
        a,b,c,d = acts[i:i+4]
        if a != b and a == c and b == d:
            ping_pong += 1; i += 2
        else:
            i += 1
    # —Ä–µ—Å—É—Ä—Å–Ω—ã–π –ø–∏–Ω–≥-–ø–æ–Ω–≥ A@R1‚ÜîA@R2
    ping_pong_res = 0
    if use_res:
        i = 0
        while i+3 < len(acts):
            a1,r1 = acts[i],res[i]; a2,r2 = acts[i+1],res[i+1]; a3,r3 = acts[i+2],res[i+2]; a4,r4 = acts[i+3],res[i+3]
            if a1 == a2 == a3 == a4 and len({r1,r2}) == 2 and r1 == r3 and r2 == r4:
                ping_pong_res += 1; i += 2
            else:
                i += 1
    returns_nonadj = 0; last_pos = {}
    for j,a in enumerate(acts):
        if a in last_pos and j-last_pos[a] > 1:
            returns_nonadj += 1
        last_pos[a] = j
    jump_to_prev_any = 0; seen = set()
    for j in range(len(acts)-1):
        seen.add(acts[j])
        if acts[j+1] in seen and acts[j+1] != acts[j]:
            jump_to_prev_any += 1
    start_act = acts[0]
    back_to_start = sum(1 for j in range(1,len(acts)) if acts[j] == start_act)
    score = self_loops + ping_pong + ping_pong_res + returns_nonadj + jump_to_prev_any + back_to_start
    return dict(self_loops=self_loops,ping_pong=ping_pong,ping_pong_res=ping_pong_res,
                returns_nonadj=returns_nonadj,jump_to_prev_any=jump_to_prev_any,back_to_start=back_to_start,
                loop_score_advanced=score)

loop_rows = []
for cid,g in df.groupby("case_id"):
    sc = loop_subtypes_for_case(g, use_resource); sc["case_id"] = cid; loop_rows.append(sc)
loops_df = pd.DataFrame(loop_rows)

def q75(s): return int(np.ceil(safe_pct(s, 75, default=1)))
thr_self = q75(loops_df["self_loops"]); thr_pp = q75(loops_df["ping_pong"])
thr_ppr = q75(loops_df["ping_pong_res"]) if use_resource else 1
thr_ret = q75(loops_df["returns_nonadj"]); thr_jump = q75(loops_df["jump_to_prev_any"])
thr_start = q75(loops_df["back_to_start"]); thr_loop_total = q75(loops_df["loop_score_advanced"])

# =========================
# 2) –î–õ–ò–¢–ï–õ–¨–ù–û–°–¢–¨ ‚Äî –ø–æ–¥—Ç–∏–ø—ã
# =========================
def per_case_overruns(sub_edges: pd.DataFrame):
    single_spike = 0; overrun_sum = 0.0; entry_waits = {}
    for _,row in sub_edges.iterrows():
        e = (row["activity"],row["next_activity"]); d = float(row["delta_sec"])
        med = edge_median_map.get(e, np.nan); p99 = edge_p99_map.get(e, np.nan)
        if not np.isnan(med): overrun_sum += max(0.0, d-med)
        if not np.isnan(p99) and d > p99: single_spike += 1
        entry_waits[row["next_activity"]] = entry_waits.get(row["next_activity"],0.0) + d
    total_wait = sum(entry_waits.values()); queue_flag=False; qtarget=None
    if total_wait>0:
        best = max(entry_waits,key=entry_waits.get)
        if entry_waits[best]/total_wait >= 0.40: queue_flag=True; qtarget=best
    return single_spike, overrun_sum, queue_flag, qtarget

over_rows = []
for cid,g in df_sorted.groupby("case_id"):
    sub_e = g.dropna(subset=["next_activity","delta_sec"])
    ss,osum,qf,qt = per_case_overruns(sub_e)
    over_rows.append({"case_id":cid,"single_spike_cnt":ss,"overrun_sum_sec":osum,"queue_before_flag":qf,"queue_target":qt})
over_df = pd.DataFrame(over_rows)
thr_over_sum = float(np.ceil(safe_pct(over_df["overrun_sum_sec"],90,default=0.0)))
thr_over_spike = max(1,int(np.ceil(safe_pct(over_df["single_spike_cnt"],75,default=1))))

# =========================
# 3) –í–õ–ò–Ø–ù–ò–ï ‚Äî –ø–æ–¥—Ç–∏–ø—ã
# =========================
k_bottlenecks = st.sidebar.number_input("Top-k —É–∑–∫–∏—Ö —Ä—ë–±–µ—Ä (–¥–ª—è –≤–ª–∏—è–Ω–∏—è/bottleneck)", min_value=1, value=10, step=1)
top_edges = set(edge_stats.sort_values("median",ascending=False).head(k_bottlenecks)["edge"].tolist())

def impact_for_case(sub_edges: pd.DataFrame):
    if sub_edges.empty: return 0.0,0.0,0
    imp_sum=0.0; in_b=0; excnt=0; n=0
    for _,row in sub_edges.iterrows():
        e=(row["activity"],row["next_activity"]); d=float(row["delta_sec"]); p95 = edge_p95_map.get(e,np.nan)
        n+=1
        if e in top_edges: in_b += 1
        if not np.isnan(p95) and d>p95:
            imp_sum += (d-p95); excnt += 1
    share = in_b/n if n else 0.0
    return imp_sum, share, excnt

impact_rows=[]
for cid,g in df_sorted.groupby("case_id"):
    sub_e = g.dropna(subset=["next_activity","delta_sec"])
    isum,share,excnt = impact_for_case(sub_e)
    impact_rows.append({"case_id":cid,"impact_sum_sec":isum,"bneck_share":share,"p95_exceed_cnt":excnt})
impact_df = pd.DataFrame(impact_rows)
thr_impact_sum = float(np.ceil(safe_pct(impact_df["impact_sum_sec"],90,default=0.0)))
thr_bneck_share = float(np.round(safe_pct(impact_df["bneck_share"],90,default=0.5),2))
thr_exceed_cnt = int(np.ceil(safe_pct(impact_df["p95_exceed_cnt"],75,default=1)))

# =========================
# 4) –û–¢–î–ï–õ–¨–ù–´–ô –ë–õ–û–ö: BOTTLENECK-–ê–ù–ê–õ–ò–ó
# =========================
st.header("üö¶ Bottleneck-–∞–Ω–∞–ª–∏–∑ (—É–∑–∫–∏–µ –º–µ—Å—Ç–∞)")
st.markdown(
    "Bottleneck ‚Äî —ç—Ç–æ —à–∞–≥ –∏–ª–∏ –ø–µ—Ä–µ—Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π **—Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–¥–µ—Ä–∂–∏–≤–∞–µ—Ç** –∫–µ–π—Å—ã. "
    "–ú—ã —Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç—Ä–∏ —É—Ä–æ–≤–Ω—è:\n"
    "1) **–ü–µ—Ä–µ—Ö–æ–¥—ã (—Ä—ë–±—Ä–∞)**: –±–æ–ª—å—à–∏–µ –º–µ–¥–∏–∞–Ω–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è (`median Œî`) ‚Üí –≥–ª–æ–±–∞–ª—å–Ω—ã–µ ¬´—É–∑–∫–∏–µ —Ä—ë–±—Ä–∞`.\n"
    "2) **–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏**: —Å—É–º–º–∞—Ä–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –Ω–∞ –≤—Ö–æ–¥ –≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (–∏–∑ –≤—Å–µ—Ö –ø—Ä–µ–¥—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤).\n"
    "3) **–ö–µ–π—Å—ã**: –¥–æ–ª—è –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –ø–æ –≥–ª–æ–±–∞–ª—å–Ω—ã–º —É–∑–∫–∏–º —Ä—ë–±—Ä–∞–º + –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–π `p95` –∏ `impact_sum`."
)

# 4.1 –£–∑–∫–∏–µ —Ä—ë–±—Ä–∞ (–≥–ª–æ–±–∞–ª—å–Ω–æ)
edge_stats_sorted = edge_stats.sort_values("median", ascending=False)
p90_median = safe_pct(edge_stats_sorted["median"], 90, default=np.nan)
edge_stats_sorted["is_bottleneck_edge"] = edge_stats_sorted["median"] >= (p90_median if not np.isnan(p90_median) else np.inf)
st.subheader("4.1 –£–∑–∫–∏–µ —Ä—ë–±—Ä–∞ (–ø–µ—Ä–µ—Ö–æ–¥—ã)")
st.caption("–í—ã—à–µ ‚Äî —Ä—ë–±—Ä–∞ —Å —Å–∞–º—ã–º–∏ –±–æ–ª—å—à–∏–º–∏ –º–µ–¥–∏–∞–Ω–Ω—ã–º–∏ –æ–∂–∏–¥–∞–Ω–∏—è–º–∏; —Ñ–ª–∞–≥ —Å—Ç–∞–≤–∏–º –ø–æ –ø–æ—Ä–æ–≥—É p90 –æ—Ç –º–µ–¥–∏–∞–Ω.")
show_edges = edge_stats_sorted.head(20)[["edge","count","median","p95","p99","mean","std","is_bottleneck_edge"]]
st.dataframe(show_edges, use_container_width=True)
# –≤—ã–≥—Ä—É–∑–∫–∞
st.download_button("‚¨áÔ∏è CSV ‚Äî —Ä—ë–±—Ä–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏",
                   edge_stats_sorted.to_csv(index=False).encode("utf-8"),
                   file_name="bottleneck_edges_metrics.csv",
                   mime="text/csv", key="dl_edges_csv")

# 4.2 –£–∑–∫–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (—Å—É–º–º–∞—Ä–Ω—ã–µ –≤—Ö–æ–¥—è—â–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è)
incoming_wait = edges.groupby("next_activity")["delta_sec"].agg(total_wait="sum", mean_wait="mean", median_wait="median", cnt="count").reset_index()
p90_in_total = safe_pct(incoming_wait["total_wait"], 90, default=np.nan)
incoming_wait["is_bottleneck_activity"] = incoming_wait["total_wait"] >= (p90_in_total if not np.isnan(p90_in_total) else np.inf)
st.subheader("4.2 –£–∑–∫–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (–ø–æ —Å—É–º–º–µ –æ–∂–∏–¥–∞–Ω–∏–π –Ω–∞ –≤—Ö–æ–¥)")
st.dataframe(incoming_wait.sort_values("total_wait", ascending=False).head(20), use_container_width=True)
st.download_button("‚¨áÔ∏è CSV ‚Äî –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å –≤—Ö–æ–¥—è—â–∏–º–∏ –æ–∂–∏–¥–∞–Ω–∏—è–º–∏",
                   incoming_wait.to_csv(index=False).encode("utf-8"),
                   file_name="bottleneck_activities_metrics.csv",
                   mime="text/csv", key="dl_acts_csv")

# 4.3 –ö–µ–π—Å—ã, –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ —É–∑–∫–∏–º–∏ —Ä—ë–±—Ä–∞–º–∏
st.subheader("4.3 –ö–µ–π—Å—ã, –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ —É–∑–∫–∏–º–∏ —Ä—ë–±—Ä–∞–º–∏")
bneck_edges_set = set(edge_stats_sorted[edge_stats_sorted["is_bottleneck_edge"]]["edge"].tolist())
def case_bneck_involvement(sub_edges: pd.DataFrame):
    if sub_edges.empty: return 0.0, 0, 0.0
    n = sub_edges.shape[0]
    hits = sub_edges["edge"].isin(bneck_edges_set).sum()
    share = hits / n if n else 0.0
    total_wait_on_bneck = sub_edges.loc[sub_edges["edge"].isin(bneck_edges_set), "delta_sec"].sum()
    return share, hits, total_wait_on_bneck

case_rows = []
for cid, g in edges.groupby("case_id"):
    share, hits, wait_sum = case_bneck_involvement(g[["edge","delta_sec"]].assign(edge=g["edge"]))
    case_rows.append({"case_id": cid, "bneck_edge_share": share, "bneck_edge_hits": hits, "bneck_wait_sum": wait_sum})
case_bneck_df = pd.DataFrame(case_rows)
auto_case_bneck_share_thr = float(np.round(safe_pct(case_bneck_df["bneck_edge_share"], 90, default=0.5), 2))
auto_case_bneck_wait_thr  = float(np.ceil(safe_pct(case_bneck_df["bneck_wait_sum"], 90, default=0.0)))

st.write(f"–ê–≤—Ç–æ–ø–æ—Ä–æ–≥–∏: –¥–æ–ª—è —É–∑–∫–∏—Ö —Ä—ë–±–µ—Ä **‚â• {auto_case_bneck_share_thr:.2f}** –∏–ª–∏ —Å—É–º–º–∞ –æ–∂–∏–¥–∞–Ω–∏–π –Ω–∞ –Ω–∏—Ö **‚â• {int(auto_case_bneck_wait_thr)} —Å–µ–∫**.")
case_bneck_df["flag_case_bneck"] = (case_bneck_df["bneck_edge_share"] >= auto_case_bneck_share_thr) | \
                                   (case_bneck_df["bneck_wait_sum"]  >= auto_case_bneck_wait_thr)
n_bad_bneck_cases = int(case_bneck_df["flag_case_bneck"].sum())
st.write(f"–ù–∞–ª–∏—á–∏–µ –∫–µ–π—Å–æ–≤, –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã—Ö bottleneck-–∞–º–∏: **{'–î–∞' if n_bad_bneck_cases>0 else '–ù–µ—Ç'}** ‚Ä¢ –∫–µ–π—Å–æ–≤: **{n_bad_bneck_cases}** –∏–∑ {n_cases}")

if n_bad_bneck_cases > 0:
    show = case_bneck_df[case_bneck_df["flag_case_bneck"]].sort_values(
        ["bneck_edge_share","bneck_wait_sum"], ascending=False
    ).head(5)
    st.markdown("**–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–µ–π—Å—ã:**")
    for _, r in show.iterrows():
        st.markdown(f"- **{r['case_id']}** ‚Äî –¥–æ–ª—è —É–∑–∫–∏—Ö —Ä—ë–±–µ—Ä={r['bneck_edge_share']:.2f}, –æ–∂–∏–¥–∞–Ω–∏–µ –Ω–∞ –Ω–∏—Ö={int(r['bneck_wait_sum'])} —Å–µ–∫")
st.download_button("‚¨áÔ∏è CSV ‚Äî –∫–µ–π—Å—ã –∏ –∏—Ö –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å –≤ bottlenecks",
                   case_bneck_df.to_csv(index=False).encode("utf-8"),
                   file_name="bottleneck_cases_involvement.csv",
                   mime="text/csv", key="dl_cases_csv")

# =========================
# DFG: –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è —Å—Ö–µ–º–∞ + –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∫–Ω–æ–ø–∫–∏ –≤—ã–≥—Ä—É–∑–∫–∏
# =========================
with st.expander("üìå –ö–∞—Ä—Ç–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ (DFG) –∏ —ç–∫—Å–ø–æ—Ä—Ç", expanded=True):
    dfg_mode = st.radio("–ú–µ—Ç—Ä–∏–∫–∞ –∫–∞—Ä—Ç—ã", ["Frequency", "Performance"], horizontal=True, key="dfg_mode")
    if dfg_mode == "Frequency":
        dfg, sa, ea = pm4py.discover_dfg(event_log); variant = dfg_visualizer.Variants.FREQUENCY
    else:
        dfg, sa, ea = pm4py.discover_performance_dfg(event_log); variant = dfg_visualizer.Variants.PERFORMANCE

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏/–ø–ª–æ—Ç–Ω–æ—Å—Ç–∏
    st.caption("–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞")
    c1,c2,c3,c4 = st.columns(4)
    with c1:
        rankdir = st.selectbox("–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è", ["TB (—Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑)","LR (—Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ)"], index=0, key="rankdir_sel")
    with c2:
        ranksep = st.slider("ranksep", 0.1, 3.0, 0.6, 0.1, key="ranksep_sl")
    with c3:
        nodesep = st.slider("nodesep", 0.05, 2.0, 0.2, 0.05, key="nodesep_sl")
    with c4:
        ratio = st.selectbox("ratio", ["compress","fill","auto"], index=0, key="ratio_sel")

    params = {"start_activities": sa, "end_activities": ea}
    gviz = dfg_visualizer.apply(dfg, log=event_log, variant=variant, parameters=params)

    # –≤–µ—Ä—Ç–∏–∫–∞–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    gviz.graph_attr.update(rankdir=("TB" if rankdir.startswith("TB") else "LR"),
                           ranksep=str(ranksep), nodesep=str(nodesep), ratio=ratio)

    st.graphviz_chart(gviz.source, use_container_width=True)

    # --- –ö–Ω–æ–ø–∫–∏ –≤—ã–≥—Ä—É–∑–∫–∏ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ) ---
    # DOT ‚Äî —Ç–µ–∫—Å—Ç, –æ—Ç–¥–µ–ª—å–Ω—ã–π –±—É—Ñ–µ—Ä
    dot_bytes = gviz.source.encode("utf-8")
    st.download_button("‚¨áÔ∏è DOT", dot_bytes, file_name="process_dfg.dot", mime="text/plain", key="dl_dot_btn")

    has_dot = shutil.which("dot") is not None

    # PNG —á–µ—Ä–µ–∑ graphviz ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –æ—Ç–¥–µ–ª—å–Ω—ã–π read (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º gviz.source!)
    if has_dot:
        try:
            with tempfile.TemporaryDirectory() as tmpd:
                outpath = os.path.join(tmpd, "process_dfg")
                gviz.render(filename=outpath, format="png", cleanup=True)
                png_path = outpath + ".png"
                with open(png_path, "rb") as f_png:
                    png_data = f_png.read()
                st.download_button("‚¨áÔ∏è PNG (graphviz)", png_data, file_name="process_dfg.png",
                                   mime="image/png", key="dl_png_gv_btn")
        except Exception as e:
            st.warning(f"PNG —á–µ—Ä–µ–∑ graphviz –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")

    # Fallback PNG ‚Äî —Ä–∏—Å—É–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É —Å–∞–º–∏
    if not has_dot:
        st.info("Graphviz ('dot') –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Ä–∏—Å—É—é –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π PNG (fallback).")
        try:
            G = nx.DiGraph()
            for (u, v), w in dfg.items():
                G.add_edge(str(u), str(v), weight=w)
            try:
                layers = list(nx.algorithms.dag.topological_generations(G))
            except Exception:
                layers = [list(G.nodes())]
            pos = {}
            y = 0
            for layer in layers:
                for i, n in enumerate(layer):
                    pos[n] = (i, -y)
                y += 1
            fig, ax = plt.subplots(figsize=(8, 14))  # –≤—ã—Å–æ–∫–∏–π —Ä–∏—Å—É–Ω–æ–∫
            nx.draw_networkx_nodes(G, pos, node_size=1200, ax=ax)
            nx.draw_networkx_labels(G, pos, font_size=8, ax=ax)
            nx.draw_networkx_edges(G, pos, arrows=True, arrowstyle='-|>', ax=ax)
            edge_labels = {(u, v): f"{data.get('weight', '')}" for u, v, data in G.edges(data=True)}
            nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=7, ax=ax)
            ax.axis('off')
            buf_png = io.BytesIO()
            plt.tight_layout()
            fig.savefig(buf_png, format="png", dpi=200)
            buf_png.seek(0)
            st.download_button("‚¨áÔ∏è PNG (fallback, –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π)", buf_png.getvalue(),
                               file_name="process_dfg_fallback_vertical.png",
                               mime="image/png", key="dl_png_fb_btn")
            st.pyplot(fig, use_container_width=True)
        except Exception as e:
            st.warning(f"–§–æ–ª–ª–±—ç–∫ PNG –Ω–µ —É–¥–∞–ª—Å—è: {e}. –£—Å—Ç–∞–Ω–æ–≤–∏ `graphviz` –¥–ª—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ —ç–∫—Å–ø–æ—Ä—Ç–∞.")
